{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5481 - Tutorial 3\n",
    "## Data Preprocessing and Regularization Expression\n",
    "\n",
    "Welcome to CS5481 tutorial. In this tutorial, you will learn to how to prerpocess data you colleted with Pandas and be familar with Regular Expression and utilize it to process text data.\n",
    "\n",
    "## Preparation\n",
    "- Python\n",
    "- Python Libraries\n",
    "- - Pandas\n",
    "- - re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-18T03:28:17.230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/fanli/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/fanli/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fanli/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/fanli/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/fanli/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:28:53.632817Z",
     "start_time": "2023-09-18T03:28:53.034836Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "- Data Cleaning\n",
    "\n",
    "Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data. Data cleansing may be performed interactively with data wrangling tools, or as batch processing through scripting or a data quality firewall.\n",
    "\n",
    "- Data Integration\n",
    "\n",
    "Data reduction is the transformation of numerical or alphabetical digital information derived empirically or experimentally into a corrected, ordered, and simplified form. The purpose of data reduction can be two-fold: reduce the number of data records by eliminating invalid data or produce summary data and statistics at different aggregation levels for various applications.\n",
    "\n",
    "- Data Transformation\n",
    "\n",
    "In computing, data transformation is the process of converting data from one format or structure into another format or structure. This step's purpose is to provide data easier to be processed by the following process steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleaning\n",
    "- Basic Operations\n",
    "- Check NAN Data\n",
    "- Check Unreasonable Data\n",
    "- Check Replicated Data\n",
    "- Constrain Data Type\n",
    "- Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:33:58.665755Z",
     "start_time": "2023-09-18T03:33:58.598859Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movie_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_metadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movie_metadata.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'movie_metadata.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:34:02.565803Z",
     "start_time": "2023-09-18T03:34:02.510710Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the first 5 lines of the file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:34:04.255414Z",
     "start_time": "2023-09-18T03:34:04.206760Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the last 5 lines of the file\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:34:07.023407Z",
     "start_time": "2023-09-18T03:34:06.998476Z"
    }
   },
   "outputs": [],
   "source": [
    "# check stat info of columns: data.columnname.describe()\n",
    "data.duration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:38:51.325376Z",
     "start_time": "2023-09-18T03:38:51.311134Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose a column: data[columnname]\n",
    "data['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:38:54.516852Z",
     "start_time": "2023-09-18T03:38:54.492521Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose the first K lines: data['columnname'][:K]\n",
    "K = 10\n",
    "data[\"color\"][:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:39:08.441758Z",
     "start_time": "2023-09-18T03:39:08.415829Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose multiple columns: data[[\"column1\", \"column2\"]]\n",
    "data[[\"color\", \"director_name\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:40:36.171107Z",
     "start_time": "2023-09-18T03:40:36.105984Z"
    }
   },
   "outputs": [],
   "source": [
    "# where filtering: data[data['columnname'] > condition]\n",
    "# choose films whose duration is larger than 150 mins\n",
    "data[data[\"duration\"] > 150]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process NAN Data\n",
    "1. fill value \n",
    "2. remove corresponding lines\n",
    "3. remove columns where many values are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:40:39.165689Z",
     "start_time": "2023-09-18T03:40:39.113922Z"
    }
   },
   "outputs": [],
   "source": [
    "# check all nan data\n",
    "data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:40:43.044017Z",
     "start_time": "2023-09-18T03:40:43.023342Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill data with suitable values\n",
    "# for example, use \"\" to replace nan values in column \"country\"\n",
    "data.country = data.country.fillna(\"\")\n",
    "print(data.country)\n",
    "# use mean duration to replace nan values in column \"duration\"\n",
    "data.duration = data.duration.fillna(data.duration.mean())\n",
    "print(data.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:00.088219Z",
     "start_time": "2023-09-18T03:41:00.019817Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove lines where some values are nan\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:02.580068Z",
     "start_time": "2023-09-18T03:41:02.459971Z"
    }
   },
   "outputs": [],
   "source": [
    "# droping lines where just some values are nan is aggressive, so we can just remove lines where all values are nan.\n",
    "data.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:04.380118Z",
     "start_time": "2023-09-18T03:41:04.220510Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can also add some limitations, save lines where more than 25 values are not nan\n",
    "data.dropna(thresh=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:05.383611Z",
     "start_time": "2023-09-18T03:41:05.229722Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can remove columns where all values are nan\n",
    "data.dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:06.252799Z",
     "start_time": "2023-09-18T03:41:06.167587Z"
    }
   },
   "outputs": [],
   "source": [
    "# or remove columns where some values are nan\n",
    "data.dropna(axis=1, how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Unreasonable Data\n",
    "1. Time\n",
    "2. Values with a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:36.472688Z",
     "start_time": "2023-09-18T03:41:36.319594Z"
    }
   },
   "outputs": [],
   "source": [
    "# check title_year\n",
    "data[data[\"title_year\"] > 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:45.541677Z",
     "start_time": "2023-09-18T03:41:45.510770Z"
    }
   },
   "outputs": [],
   "source": [
    "# check imdb_score\n",
    "data[data[\"imdb_score\"] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Replicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:41:53.447219Z",
     "start_time": "2023-09-18T03:41:53.391774Z"
    }
   },
   "outputs": [],
   "source": [
    "# check duplicated data\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:42:01.062354Z",
     "start_time": "2023-09-18T03:42:01.036206Z"
    }
   },
   "outputs": [],
   "source": [
    "# There is no duplicated lines in this file, thus we use a demo data to show how process it.\n",
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:42:02.016556Z",
     "start_time": "2023-09-18T03:42:02.000715Z"
    }
   },
   "outputs": [],
   "source": [
    "# By default, for each set of duplicated values, the first occurrence is set on False and all others on True.\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:42:05.815667Z",
     "start_time": "2023-09-18T03:42:05.796669Z"
    }
   },
   "outputs": [],
   "source": [
    "# By using ‘last’, the last occurrence of each set of duplicated values is set on False and all others on True.\n",
    "df.duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:42:09.517275Z",
     "start_time": "2023-09-18T03:42:09.485835Z"
    }
   },
   "outputs": [],
   "source": [
    "# By setting keep on False, all duplicates are True.\n",
    "df.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:42:13.522460Z",
     "start_time": "2023-09-18T03:42:13.507489Z"
    }
   },
   "outputs": [],
   "source": [
    "# To find duplicates on specific column(s), use subset.\n",
    "df.duplicated(subset=['brand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constrain Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:44:34.776087Z",
     "start_time": "2023-09-18T03:44:34.629436Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can assume we know some columns' types and we can predefine it when reading data\n",
    "data = pd.read_csv(r'movie_metadata.csv', dtype={'num_voted_users': int, \"title_year\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:44:41.134748Z",
     "start_time": "2023-09-18T03:44:41.089632Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can also rename columns for human understanding\n",
    "data = data.rename(columns = {'title_year':'release_date', 'movie_facebook_likes':'facebook_likes'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:45:23.357452Z",
     "start_time": "2023-09-18T03:45:23.214830Z"
    }
   },
   "outputs": [],
   "source": [
    "# after clean the data, we usually need to save the cleaned data to a new file\n",
    "data.to_csv('cleanfile.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:46:39.515799Z",
     "start_time": "2023-09-18T03:46:39.448042Z"
    }
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'key':['b','b','a','c','a','a','b'],'data1':range(7)})\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:46:48.916997Z",
     "start_time": "2023-09-18T03:46:48.851700Z"
    }
   },
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({'key':['a','b','d'],'data2':range(3)})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:46:59.724261Z",
     "start_time": "2023-09-18T03:46:59.663746Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can merge two datasets with pd.merge(), the default merged column is the common column\n",
    "pd.merge(df1, df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:13.071316Z",
     "start_time": "2023-09-18T03:47:13.047754Z"
    }
   },
   "outputs": [],
   "source": [
    "# of course, we could give the merged column\n",
    "pd.merge(df1,df2,on='key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:14.013049Z",
     "start_time": "2023-09-18T03:47:13.992690Z"
    }
   },
   "outputs": [],
   "source": [
    "# we could merge two datasets with different columns\n",
    "df3=pd.DataFrame({'1key':['b','b','a','c','a','a','b'],'data1':range(7)})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:15.914926Z",
     "start_time": "2023-09-18T03:47:15.857720Z"
    }
   },
   "outputs": [],
   "source": [
    "df4=pd.DataFrame({'2key':['a','b','d'],'data2':range(3)})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:17.076458Z",
     "start_time": "2023-09-18T03:47:17.052756Z"
    }
   },
   "outputs": [],
   "source": [
    "# default mode keeps the cross set of key values, which is called inner connection\n",
    "pd.merge(df3,df4,left_on='1key',right_on='2key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:18.436687Z",
     "start_time": "2023-09-18T03:47:18.348378Z"
    }
   },
   "outputs": [],
   "source": [
    "# when merge two datasets with outer connection\n",
    "pd.merge(df1,df2,on='key',how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Transformation\n",
    "- String Transformation\n",
    "- Number Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- String Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:26.817624Z",
     "start_time": "2023-09-18T03:47:26.748509Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper case\n",
    "data[\"director_name\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:28.230447Z",
     "start_time": "2023-09-18T03:47:28.210928Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper case\n",
    "data[\"director_name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:28.991430Z",
     "start_time": "2023-09-18T03:47:28.969436Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove special strings for whitespace, \\n\n",
    "data['movie_title'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:30.814883Z",
     "start_time": "2023-09-18T03:47:30.769872Z"
    }
   },
   "outputs": [],
   "source": [
    "# unit transformation\n",
    "\n",
    "data[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:31.515954Z",
     "start_time": "2023-09-18T03:47:31.433241Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"duration\"] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:32.022681Z",
     "start_time": "2023-09-18T03:47:31.926876Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "norm_duration = (data.duration - data.duration.min()) / (data.duration.max() - data.duration.min())\n",
    "norm_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:47:32.721861Z",
     "start_time": "2023-09-18T03:47:32.652216Z"
    }
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "std_duration = (data.duration - data.duration.mean()) / data.duration.std()\n",
    "std_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretization\n",
    "# qcut: divie data points into M groups and each group has the same number of data points\n",
    "m_cut = pd.qcut(data.duration, 5)\n",
    "m_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regularization Expression\n",
    "1.Metacharacters\n",
    "- [] &emsp;&emsp; A set of characters\n",
    "- \\\t&emsp;&emsp; Signals a special sequence (can also be used to escape special characters)\n",
    "- .\t&emsp;&emsp; Any character (except newline character)\t\"he..o\"\t\n",
    "- ^\t&emsp;&emsp; Starts with \"^hello\"\t\n",
    "- Ends with \"planet\\$\"\n",
    "- \\* &emsp;&emsp; Zero or more occurrences\t\"he.*o\"\t\n",
    "- \\+ &emsp;&emsp; One or more occurrences\t\"he.+o\"\t\n",
    "- ?\t&emsp;&emsp; Zero or one occurrences\t\"he.?o\"\t\n",
    "- {} &emsp;&emsp; Exactly the specified number of occurrences\t\"he.{2}o\"\t\n",
    "- |\t&emsp;&emsp; Either or\t\"falls|stays\"\t\n",
    "- () &emsp;&emsp; Capture and group\n",
    "\n",
    "2.Special Sequences\n",
    "- \\A\t&emsp;&emsp; Returns a match if the specified characters are at the beginning of the string\t\"\\AThe\"\t\n",
    "- \\b\t&emsp;&emsp; Returns a match where the specified characters are at the beginning or at the end of a word\n",
    "(the \"r\" in the beginning is making sure that the string is being treated as a \"raw string\")\tr\"\\bain\"\n",
    "r\"ain\\b\"\t\n",
    "- \\B\t&emsp;&emsp; Returns a match where the specified characters are present, but NOT at the beginning (or at the end) of a word\n",
    "(the \"r\" in the beginning is making sure that the string is being treated as a \"raw string\")\tr\"\\Bain\"\n",
    "r\"ain\\B\"\t\n",
    "- \\d\t&emsp;&emsp; Returns a match where the string contains digits (numbers from 0-9)\t\"\\d\"\t\n",
    "- \\D\t&emsp;&emsp; Returns a match where the string DOES NOT contain digits\t\"\\D\"\t\n",
    "- \\s\t&emsp;&emsp; Returns a match where the string contains a white space character\t\"\\s\"\t\n",
    "- \\S\t&emsp;&emsp; Returns a match where the string DOES NOT contain a white space character\t\"\\S\"\t\n",
    "- \\w\t&emsp;&emsp; Returns a match where the string contains any word characters (characters from a to Z, digits from 0-9, and the underscore _ character)\t\"\\w\"\t\n",
    "- \\W\t&emsp;&emsp; Returns a match where the string DOES NOT contain any word characters\t\"\\W\"\t\n",
    "- \\Z\t&emsp;&emsp; Returns a match if the specified characters are at the end of the string\n",
    "\n",
    "3.Sets\n",
    "- [arn]\t&emsp;&emsp; Returns a match where one of the specified characters (a, r, or n) is present\t\n",
    "- [a-n]\t&emsp;&emsp; Returns a match for any lower case character, alphabetically between a and n\t\n",
    "- [^arn] &emsp;&emsp; Returns a match for any character EXCEPT a, r, and n\t\n",
    "- [0123] &emsp;&emsp; Returns a match where any of the specified digits (0, 1, 2, or 3) are present\t\n",
    "- [0-9]\t&emsp;&emsp; Returns a match for any digit between 0 and 9\t\n",
    "- [0-5][0-9] &emsp;&emsp; Returns a match for any two-digit numbers from 00 and 59\t\n",
    "- [a-zA-Z] &emsp;&emsp; Returns a match for any character alphabetically between a and z, lower case OR upper case\t\n",
    "- [+] &emsp;&emsp; In sets, +, *, ., |, (), $,{} has no special meaning, so [+] means: return a match for any + character in the string\n",
    "\n",
    "4.Funtions\n",
    "- The findall() function returns a list containing all matches.\n",
    "- The search() function searches the string for a match, and returns a Match object if there is a match. If there is more than one match, only the first occurrence of the match will be returned. If no matches are found, the value None is returned.\n",
    "- The split() function returns a list where the string has been split at each match.\n",
    "- The sub() function replaces the matches with the text of your choice.\n",
    "\n",
    "5.Ojects\n",
    "- A Match Object is an object containing information about the search and the result.\n",
    "- The Match object has properties and methods used to retrieve information about the search, and the result:\n",
    "\n",
    "- .span() returns a tuple containing the start-, and end positions of the match.\n",
    "\n",
    "- .string returns the string passed into the function\n",
    "\n",
    "- .group() returns the part of the string where there was a match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:12.049857Z",
     "start_time": "2023-09-18T03:48:12.043616Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:12.614389Z",
     "start_time": "2023-09-18T03:48:12.583682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'ai']\n"
     ]
    }
   ],
   "source": [
    "# findall function\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.findall(\"ai\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:13.213704Z",
     "start_time": "2023-09-18T03:48:13.165424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Return an empty list if no match was found:\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.findall(\"Portugal\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:13.815165Z",
     "start_time": "2023-09-18T03:48:13.761650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first white-space character is located in position: 3\n"
     ]
    }
   ],
   "source": [
    "# search function\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"\\s\", txt)\n",
    "\n",
    "print(\"The first white-space character is located in position:\", x.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:14.294609Z",
     "start_time": "2023-09-18T03:48:14.286784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# If no matches are found, the value None is returned: \n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"Portugal\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:15.020439Z",
     "start_time": "2023-09-18T03:48:15.012276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'rain', 'in', 'Spain']\n"
     ]
    }
   ],
   "source": [
    "# split function\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.split(\"\\s\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:15.514395Z",
     "start_time": "2023-09-18T03:48:15.416765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'rain in Spain']\n"
     ]
    }
   ],
   "source": [
    "# Split the string only at the first occurrence:\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.split(\"\\s\", txt, 1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:16.714523Z",
     "start_time": "2023-09-18T03:48:16.637813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The9rain9in9Spain\n"
     ]
    }
   ],
   "source": [
    "# Replace every white-space character with the number 9:\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.sub(\"\\s\", \"9\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:17.714569Z",
     "start_time": "2023-09-18T03:48:17.646947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The9rain9in Spain\n"
     ]
    }
   ],
   "source": [
    "# Replace the first 2 occurrences:\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.sub(\"\\s\", \"9\", txt, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:18.316287Z",
     "start_time": "2023-09-18T03:48:18.307583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 7), match='ai'>\n"
     ]
    }
   ],
   "source": [
    "# Do a search that will return a Match Object:\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"ai\", txt)\n",
    "print(x) #this will print an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:19.002495Z",
     "start_time": "2023-09-18T03:48:18.993177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the position (start- and end-position) of the first match occurrence.\n",
    "# The regular expression looks for any words that starts with an upper case \"S\":\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(r\"\\bS\\w+\", txt)\n",
    "print(x.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:19.813881Z",
     "start_time": "2023-09-18T03:48:19.779228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rain in Spain\n"
     ]
    }
   ],
   "source": [
    "# Print the string passed into the function:\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(r\"\\bS\\w+\", txt)\n",
    "print(x.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:20.914398Z",
     "start_time": "2023-09-18T03:48:20.874691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain\n"
     ]
    }
   ],
   "source": [
    "# Print the part of the string where there was a match.\n",
    "# The regular expression looks for any words that starts with an upper case \"S\":\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(r\"\\bS\\w+\", txt)\n",
    "print(x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:48:22.314638Z",
     "start_time": "2023-09-18T03:48:22.223651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test@outlook.com', '123456@qq.com']\n"
     ]
    }
   ],
   "source": [
    "# Construction a regular expression which could extract e-mail\n",
    "pattern = re.compile(r\"[a-zA-Z0-9_-]+@[a-zA-Z0-9_-]+(?:\\.[a-zA-Z0-9_-]+)\")\n",
    "\n",
    "strs = 'My personal e-mail is test@outlook.com, company e-mail is 123456@qq.com'\n",
    "result = pattern.findall(strs)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3, 4, ],\n",
    "     [2, 3, 4, 5, 6],\n",
    "     [3, 4, 5, 6, 7]]\n",
    "data = pd.DataFrame(a)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the normalized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the standarized data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:22:05.915456Z",
     "start_time": "2023-09-18T03:22:05.884455Z"
    }
   },
   "source": [
    "**regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T03:20:34.514476Z",
     "start_time": "2023-09-18T03:20:34.444321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct a regular expression which could extract date\n",
    "pattern =                  #insert your answer here\n",
    "strs = 'Today is 2022/09/13, today in the last year is 2021.09.13, today in the next year is 2023-09-13'\n",
    "result =                   #insert your answer here\n",
    "print(result)\n",
    "# The answer is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
